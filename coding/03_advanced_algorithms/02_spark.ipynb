{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/robbie/miniconda3/envs/dhbw-3-big-data/lib/python3.11/site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/robbie/miniconda3/envs/dhbw-3-big-data/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark - Map Reduce Beispiel\n",
    "\n",
    "\n",
    "Nachdem wir eingangs MapReduce in Python implementiert haben, wollen wir das Ganze nun nochmal in Apache Spark implementieren.\n",
    "\n",
    "Hierfür muss zunächst Spark lokal installiert werden:\n",
    "* [für Mac](https://sparkbyexamples.com/spark/install-apache-spark-on-mac/)\n",
    "* [für Windows](https://sparkbyexamples.com/spark/apache-spark-installation-on-windows/)\n",
    "\n",
    "Diese Lokalinstallation ist nötig, um Spark-Workloads ausführen zu können (ähnlich dem gehosteten Spark auf z.B. AWS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/30 13:37:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem: 1\n",
      "ipsum: 6\n",
      "dolor: 3\n",
      "sit: 9\n",
      "amet,: 1\n",
      "consectetur: 2\n",
      "adipiscing: 1\n",
      "elit.: 3\n",
      "Nullam: 6\n",
      "placerat,: 1\n",
      "felis: 4\n",
      "eget: 12\n",
      "mattis: 2\n",
      "accumsan,: 1\n",
      "quam: 7\n",
      "turpis: 2\n",
      "bibendum: 8\n",
      "libero,: 2\n",
      "eu: 14\n",
      "tempus: 2\n",
      "libero: 15\n",
      "ex: 7\n",
      "vel: 16\n",
      "quam.: 4\n",
      "Curabitur: 2\n",
      "laoreet,: 2\n",
      "nunc: 6\n",
      "nec: 17\n",
      "convallis: 3\n",
      "malesuada,: 2\n",
      "metus: 3\n",
      "varius: 3\n",
      "ex,: 1\n",
      "ut: 10\n",
      "scelerisque: 4\n",
      "lorem: 6\n",
      "odio: 10\n",
      "nulla.: 3\n",
      "Fusce: 2\n",
      "tristique: 5\n",
      "luctus: 3\n",
      "diam,: 1\n",
      "et: 10\n",
      "vehicula: 4\n",
      "laoreet: 6\n",
      "eget.: 2\n",
      "Nam: 1\n",
      "feugiat,: 1\n",
      "erat: 6\n",
      "a: 19\n",
      "lacinia: 6\n",
      "euismod,: 2\n",
      "purus: 7\n",
      "augue: 3\n",
      "vestibulum: 5\n",
      "arcu,: 2\n",
      "in: 15\n",
      "viverra: 4\n",
      "justo: 8\n",
      "non: 12\n",
      "libero.: 2\n",
      "Sed: 18\n",
      "massa.: 2\n",
      "velit,: 1\n",
      "cursus: 5\n",
      "justo.: 3\n",
      "Praesent: 3\n",
      "leo: 4\n",
      "eleifend: 8\n",
      "pharetra.: 2\n",
      ": 7\n",
      "Pellentesque: 1\n",
      "diam: 1\n",
      "iaculis.: 2\n",
      "vestibulum,: 1\n",
      "urna: 4\n",
      "tincidunt: 7\n",
      "dictum,: 2\n",
      "sapien: 11\n",
      "venenatis: 4\n",
      "nulla,: 1\n",
      "at: 4\n",
      "vulputate: 2\n",
      "ligula: 6\n",
      "nisi.: 2\n",
      "Nunc: 1\n",
      "fermentum,: 1\n",
      "fermentum: 2\n",
      "lacinia,: 1\n",
      "massa,: 3\n",
      "feugiat: 4\n",
      "eros.: 1\n",
      "mi: 3\n",
      "interdum: 4\n",
      "malesuada.: 1\n",
      "Donec: 5\n",
      "egestas: 3\n",
      "auctor: 5\n",
      "pellentesque: 3\n",
      "vel.: 1\n",
      "orci: 4\n",
      "mi.: 2\n",
      "Suspendisse: 4\n",
      "viverra,: 1\n",
      "condimentum: 1\n",
      "Proin: 5\n",
      "fringilla: 1\n",
      "neque: 4\n",
      "amet: 8\n",
      "arcu: 1\n",
      "volutpat,: 1\n",
      "rhoncus: 4\n",
      "egestas.: 3\n",
      "Maecenas: 1\n",
      "pharetra,: 1\n",
      "varius,: 2\n",
      "lectus,: 2\n",
      "iaculis: 1\n",
      "dui: 2\n",
      "Phasellus: 2\n",
      "aliquet: 3\n",
      "ac: 7\n",
      "Nulla: 7\n",
      "posuere: 4\n",
      "bibendum.: 3\n",
      "velit: 1\n",
      "sollicitudin: 2\n",
      "lacinia.: 2\n",
      "Morbi: 2\n",
      "ante: 4\n",
      "pharetra: 3\n",
      "dictum.: 1\n",
      "vitae: 3\n",
      "ultricies: 2\n",
      "interdum.: 1\n",
      "facilisi.: 1\n",
      "Vivamus: 7\n",
      "euismod: 2\n",
      "nisl: 3\n",
      "tellus: 1\n",
      "tincidunt,: 1\n",
      "scelerisque.: 2\n",
      "cursus,: 1\n",
      "lectus: 1\n",
      "ipsum,: 2\n",
      "ultrices: 4\n",
      "purus.: 1\n",
      "gravida: 2\n",
      "lacus: 1\n",
      "Integer: 7\n",
      "tortor: 2\n",
      "eros: 4\n",
      "varius.: 2\n",
      "dapibus.: 2\n",
      "malesuada: 5\n",
      "aliquam: 1\n",
      "finibus: 1\n",
      "risus.: 1\n",
      "Vestibulum: 3\n",
      "dignissim.: 2\n",
      "mauris: 1\n",
      "dictum: 3\n",
      "hendrerit.: 1\n",
      "Mauris: 3\n",
      "massa: 3\n",
      "blandit.: 1\n",
      "augue.: 1\n",
      "dui.: 1\n",
      "id: 3\n",
      "suscipit: 1\n",
      "tempus.: 1\n",
      "tempor: 1\n",
      "ante,: 1\n",
      "nec.: 1\n",
      "ex.: 1\n",
      "auctor,: 1\n",
      "tristique,: 2\n",
      "neque,: 1\n",
      "justo,: 1\n",
      "nulla: 3\n",
      "congue: 2\n",
      "rhoncus.: 1\n",
      "bibendum,: 2\n",
      "sapien,: 1\n",
      "pellentesque.: 1\n",
      "semper: 2\n",
      "accumsan: 1\n",
      "fringilla,: 1\n",
      "tristique.: 2\n",
      "mi,: 2\n",
      "urna.: 2\n",
      "volutpat: 1\n",
      "est,: 2\n",
      "eu.: 1\n",
      "Quisque: 2\n",
      "sagittis: 2\n",
      "orci.: 1\n",
      "efficitur,: 1\n",
      "orci,: 1\n",
      "turpis.: 1\n",
      "Etiam: 2\n",
      "sed: 1\n",
      "commodo.: 1\n",
      "sodales: 1\n",
      "euismod.: 1\n",
      "imperdiet: 1\n",
      "primis: 1\n",
      "faucibus: 1\n",
      "cubilia: 1\n",
      "Curae;: 1\n",
      "nisi: 2\n",
      "consequat.: 1\n",
      "ullamcorper.: 1\n",
      "In: 1\n",
      "hac: 1\n",
      "habitasse: 1\n",
      "platea: 1\n",
      "dictumst.: 1\n",
      "ac.: 1\n",
      "nisi,: 1\n",
      "id.: 1\n",
      "arcu.: 1\n",
      "risus: 3\n",
      "pellentesque,: 1\n",
      "vehicula.: 1\n",
      "a,: 1\n",
      "ante.: 1\n",
      "mattis.: 1\n",
      "fermentum.: 2\n",
      "egestas,: 1\n",
      "iaculis,: 1\n",
      "risus,: 1\n",
      "lectus.: 1\n",
      "nunc.: 1\n",
      "feugiat.: 1\n",
      "luctus.: 1\n",
      "aliquet,: 1\n",
      "elit,: 1\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Create a SparkContext\n",
    "sc = SparkContext(\"local\", \"WordCountExample\")\n",
    "\n",
    "# Load a text file from your local filesystem into an RDD (Resilient Distributed Dataset)\n",
    "text_file = sc.textFile(\"./input_text.txt\")\n",
    "\n",
    "# Split each line into words\n",
    "words = text_file.flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "# Assign a count of 1 to each word\n",
    "word_counts = words.map(lambda word: (word, 1))\n",
    "\n",
    "# Perform a reduce operation to count the occurrences of each word\n",
    "word_count = word_counts.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Print the word count results\n",
    "for (word, count) in word_count.collect():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Stop the SparkContext\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe: Berechnung der Quadratwerte mit PySpark\n",
    "\n",
    "Erstelle ein PySpark-Programm, das eine Liste von Zahlen in einem RDD  (Resilient Distributed Dataset) erstellt und dann die Quadratwerte dieser Zahlen berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 squared is 1\n",
      "2 squared is 4\n",
      "3 squared is 9\n",
      "4 squared is 16\n",
      "5 squared is 25\n",
      "6 squared is 36\n",
      "7 squared is 49\n",
      "8 squared is 64\n",
      "9 squared is 81\n",
      "10 squared is 100\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Erstellen eines SparkContext\n",
    "sc = SparkContext(\"local\", \"SimplePySparkTask\")\n",
    "\n",
    "# Erstellen eines RDD mit einer Liste von Zahlen\n",
    "numbers = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "squared_numbers = numbers.map(lambda x: x * x)\n",
    "\n",
    "for number, squared_number in zip(numbers.collect(), squared_numbers.collect()):\n",
    "    print(f\"{number} squared is {squared_number}\")\n",
    "\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('hector')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "442f59ff6058100981594e9535d28b46fc243840058aa6758dcff500d21b0d70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
